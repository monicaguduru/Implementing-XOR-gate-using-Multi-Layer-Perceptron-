# -*- coding: utf-8 -*-
"""m.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/0B72AS2q83-KoOUxsb2ZqR0ZmbnpGVEVWVkFtUzl3elloRnZR
"""

#Importing libraries
import math
import numpy as np
import matplotlib.pyplot as plt

# Differentiation of sigmoid
def sigmoid_derivative(x):
    return x*(1.0 - x)

#  Cost function
def cost(layer3,j):
    l3_err=outputs[j].reshape(1,-1) - layer3
    return math.pow(l3_err, 2)/2.0

# Multilayer Perceptron (Neural Network)
class NN:
    def __init__(self, inputs):
        self.inputs = inputs

        self.input_weights=np.random.random((2, 3))
        self.hidden1_weights=np.random.random((3, 2))
        self.hidden2_weights=np.random.random((2, 1))

    def train(self, inputs,outputs, epochs, learning_rate):
        losses = np.array([])
        for i in range(epochs):
            loss=0
            for j in range(len(inputs)):
                l0=inputs[j].reshape(1,-1)
                layer1=np.dot(l0, self.input_weights)
                layer1 = 1.0/(1.0 + np.exp(-layer1))
                layer2=np.dot(layer1, self.hidden1_weights)
                layer2 = 1.0/(1.0 + np.exp(-layer2))
                layer3=np.dot(layer2, self.hidden2_weights)
                layer3 = 1.0/(1.0 + np.exp(-layer3))

                loss+=cost(layer3,j)
                l3_err=outputs[j].reshape(1,-1) - layer3
                l3_delta = np.multiply(l3_err, sigmoid_derivative(layer3))

                l2_err=np.dot(l3_delta, self.hidden2_weights.T)
                l2_delta=np.multiply(l2_err, sigmoid_derivative(layer2))

                l1_err=np.dot(l2_delta, self.hidden1_weights.T)
                l1_delta=np.multiply(l1_err, sigmoid_derivative(layer1))

                self.input_weights+=learning_rate*np.dot(l0.T, l1_delta)
                self.hidden1_weights+=learning_rate*np.dot(layer1.T, l2_delta)
                self.hidden2_weights+=learning_rate*np.dot(layer2.T, l3_delta)
            losses = np.append(losses, loss)
        return losses

# Input and Target data
inputs=np.array([[0,1], [1,0], [1,1],[0,0]])
outputs=np.array([[1],[1],[0],[0]])

n=NN(inputs)
epochs = 10000
losses = n.train(inputs, outputs, epochs, learning_rate=0.2)
print(losses)